{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab28042",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1bd2d",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Librairies import\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "661d2dd5-30db-4ba5-a323-35465c385a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyTCTK import TextNet, WordNet\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3b9c1",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e70600",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Data import\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7aba9647-b891-441f-bcff-b1f662a90358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(filepath_or_buffer=\"upv1.csv\", sep=\",\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d81bafd-d9c1-4bf8-b18a-b39673cb66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Review'] = df_data['Review'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71b47864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1009 entries, 0 to 1008\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    1009 non-null   object\n",
      " 1   Rating  1009 non-null   int64 \n",
      " 2   Date    1009 non-null   object\n",
      " 3   Review  1009 non-null   object\n",
      " 4   Title   1009 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 39.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe625a",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfade9a",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Text cleaning: first part\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad18fa",
   "metadata": {},
   "source": [
    "> « It’s all about the Data. Key to any successful algorithm is a good dataset » (source : National Aeronautics and Space Administration, You Can Help Train NASA’s Rovers to Better Explore Mars | NASA.com).\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "    Before moving on to the modeling stage, there is a whole pre-processing to be done: make sure that there are no missing values, no absurd values (outliers), no duplicates, no uninterpretable characteristics, no correlation between certain variables, make sure to re-encode certain characteristics, perform format conversions, create new variables or delete old characteristics. This cleaning is the first step, crucial to start the project well, and has a direct influence on the performance and predictions of the future modeling. More and more, the notion of data quality is evoked because poor quality, unprepared or uninterpretable variables will only amplify the black box effect of certain models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cca5be",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Filter reviews, remove spaces and clean some specific characters\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d79191",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "    We make a first very light cleaning (deletion of spaces and html tags) before applying the sentimental analysis because the VADER algorithm takes into account the capital letters, the negations or the punctuation to realize the sentimental scoring.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "716e30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_space()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8b049e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_whitespace()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea6a03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").additional_cleaning(\n",
    "    add_regexs=None\n",
    ")\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").additional_cleaning(\n",
    "    add_regexs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f143170d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dharmesh Tolia</td>\n",
       "      <td>5</td>\n",
       "      <td>27-01-2024</td>\n",
       "      <td>Dabur Meswak Complete Oral Care Toothpaste is ...</td>\n",
       "      <td>t's more than just toothpaste; it's a holistic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit yadav</td>\n",
       "      <td>4</td>\n",
       "      <td>26-01-2024</td>\n",
       "      <td>Dabur Meswak Complete Oral Care Toothpaste I u...</td>\n",
       "      <td>Dabur Meswak Complete Oral Care Toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anabayan</td>\n",
       "      <td>5</td>\n",
       "      <td>29-01-2024</td>\n",
       "      <td>Unique taste and good product</td>\n",
       "      <td>Unique taste and good product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Rating        Date  \\\n",
       "0  Dharmesh Tolia       5  27-01-2024   \n",
       "1     Rohit yadav       4  26-01-2024   \n",
       "2        Anabayan       5  29-01-2024   \n",
       "\n",
       "                                              Review  \\\n",
       "0  Dabur Meswak Complete Oral Care Toothpaste is ...   \n",
       "1  Dabur Meswak Complete Oral Care Toothpaste I u...   \n",
       "2                      Unique taste and good product   \n",
       "\n",
       "                                               Title  \n",
       "0  t's more than just toothpaste; it's a holistic...  \n",
       "1         Dabur Meswak Complete Oral Care Toothpaste  \n",
       "2                      Unique taste and good product  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942b801",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5111f",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Sentiment analysis: VADER\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37cfa8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "097ad391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Score\"] = df_data[\"Review\"].apply(\n",
    "    lambda review: vader.polarity_scores(review)\n",
    ")\n",
    "df_data[\"Compound\"] = df_data[\"Score\"].apply(\n",
    "    lambda score_dict: score_dict[\"compound\"]\n",
    ")\n",
    "df_data[\"Sentiment\"] = df_data[\"Compound\"].apply(\n",
    "    lambda sent: \"positive\" if sent > 0 else (\"neutral\" if sent == 0 else \"negative\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c810aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    765\n",
       "neutral     171\n",
       "negative     73\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0425a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dharmesh Tolia</td>\n",
       "      <td>5</td>\n",
       "      <td>27-01-2024</td>\n",
       "      <td>Dabur Meswak Complete Oral Care Toothpaste is ...</td>\n",
       "      <td>t's more than just toothpaste; it's a holistic...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit yadav</td>\n",
       "      <td>4</td>\n",
       "      <td>26-01-2024</td>\n",
       "      <td>Dabur Meswak Complete Oral Care Toothpaste I u...</td>\n",
       "      <td>Dabur Meswak Complete Oral Care Toothpaste</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.57, 'pos': 0.43, 'compou...</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anabayan</td>\n",
       "      <td>5</td>\n",
       "      <td>29-01-2024</td>\n",
       "      <td>Unique taste and good product</td>\n",
       "      <td>Unique taste and good product</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Rating        Date  \\\n",
       "0  Dharmesh Tolia       5  27-01-2024   \n",
       "1     Rohit yadav       4  26-01-2024   \n",
       "2        Anabayan       5  29-01-2024   \n",
       "\n",
       "                                              Review  \\\n",
       "0  Dabur Meswak Complete Oral Care Toothpaste is ...   \n",
       "1  Dabur Meswak Complete Oral Care Toothpaste I u...   \n",
       "2                      Unique taste and good product   \n",
       "\n",
       "                                               Title  \\\n",
       "0  t's more than just toothpaste; it's a holistic...   \n",
       "1         Dabur Meswak Complete Oral Care Toothpaste   \n",
       "2                      Unique taste and good product   \n",
       "\n",
       "                                               Score  Compound Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...    0.9879  positive  \n",
       "1  {'neg': 0.0, 'neu': 0.57, 'pos': 0.43, 'compou...    0.9575  positive  \n",
       "2  {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...    0.4404  positive  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e485edb",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f005cdf",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Text cleaning: second part\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb444c",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Lowercase\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78159f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").lowercase()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").lowercase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14105d15",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Punctuation\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "657d66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_punctuation()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_punctuation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce305b",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            3) Specific cleaning\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f080a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_url()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0548c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_html()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35380d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_email()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e6d16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_digit()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_digit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5581301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_mention()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_mention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e564d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_hastag()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_hastag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "114014b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_emoji()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_emoji()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ddfc1",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            4) Remove stopwords\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f92c438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_to_keep = [\n",
    "    \"doesn\", \"doesn't\", \"doesnt\", \"dont\", \"don't\", \"not\", \"wasn't\", \"wasnt\",\n",
    "    \"aren\", \"aren't\", \"arent\",  \"couldn\", \"couldn't\", \"couldnt\", \"didn\",\n",
    "    \"didn't\", \"didnt\", \"hadn\", \"hadn't\", \"hadnt\",  \"hasn\", \"hasn't\", \"hasnt\",\n",
    "    \"haven't\", \"havent\", \"isn\", \"isn't\", \"isnt\", \"mightn\",  \"mightn't\",\n",
    "    \"mightnt\", \"mustn\", \"mustn't\", \"mustnt\", \"needn\", \"needn't\", \"neednt\",\n",
    "    \"shan\", \"shan't\", \"shant\", \"shouldn\", \"shouldn't\", \"shouldnt\", \"wasn\",\n",
    "    \"wasn't\",  \"wasnt\", \"weren\", \"weren't\", \"werent\", \"won\", \"won't\", \"wont\",\n",
    "    \"wouldn\", \"wouldn't\", \"wouldnt\", \"good\", \"bad\", \"worst\", \"wonderfull\",\n",
    "    \"best\", \"better\"\n",
    "]\n",
    "\n",
    "stopwords_to_add = [\n",
    "    \"es\", \"que\", \"en\", \"la\", \"las\", \"le\", \"les\", \"lo\", \"los\", \"de\", \"no\",\n",
    "    \"el\", \"al\", \"un\", \"una\", \"se\", \"sa\", \"su\", \"sus\", \"por\", \"con\", \"mi\",\n",
    "    \"para\", \"todo\", \"gb\", \"laptop\", \"computer\", \"pc\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ccefe527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = WordNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_stopword(\n",
    "    language=\"english\",\n",
    "    lowercase=False,\n",
    "    remove_accents=False,\n",
    "    add_stopwords=stopwords_to_add,\n",
    "    remove_stopwords=stopwords_to_keep\n",
    ")\n",
    "\n",
    "df_data = WordNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_stopword(\n",
    "    language=\"english\",\n",
    "    lowercase=False,\n",
    "    remove_accents=False,\n",
    "    add_stopwords=stopwords_to_add,\n",
    "    remove_stopwords=stopwords_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4745b",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            5) Lemmatization process\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7cef3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = WordNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").lemmatize(\n",
    "    language=\"english\",\n",
    "    lowercase=False,\n",
    "    remove_accents=False\n",
    ")\n",
    "\n",
    "df_data = WordNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").lemmatize(\n",
    "    language=\"english\",\n",
    "    lowercase=False,\n",
    "    remove_accents=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46663e48",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            6) Empty lines\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6613c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data.drop(index=[282, 749, 859, 883, 1013, 1014, 1061], axis=0, inplace=True)\n",
    "df_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13de0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Review\"\n",
    ").remove_whitespace()\n",
    "\n",
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"Title\"\n",
    ").remove_whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d194c47d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dharmesh Tolia</td>\n",
       "      <td>5</td>\n",
       "      <td>27-01-2024</td>\n",
       "      <td>dabur meswak complete oral care toothpaste gam...</td>\n",
       "      <td>toothpaste holistic approach oral care</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit yadav</td>\n",
       "      <td>4</td>\n",
       "      <td>26-01-2024</td>\n",
       "      <td>dabur meswak complete oral care toothpaste use...</td>\n",
       "      <td>dabur meswak complete oral care toothpaste</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.57, 'pos': 0.43, 'compou...</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anabayan</td>\n",
       "      <td>5</td>\n",
       "      <td>29-01-2024</td>\n",
       "      <td>unique taste good product</td>\n",
       "      <td>unique taste good product</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Placeholder</td>\n",
       "      <td>5</td>\n",
       "      <td>29-12-2023</td>\n",
       "      <td>first time use product nice</td>\n",
       "      <td>good product</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.646, 'pos': 0.354, 'comp...</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>04-01-2024</td>\n",
       "      <td>quality definitely since start product disappo...</td>\n",
       "      <td>use better</td>\n",
       "      <td>{'neg': 0.196, 'neu': 0.633, 'pos': 0.171, 'co...</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vinay sainath reddy</td>\n",
       "      <td>4</td>\n",
       "      <td>02-02-2024</td>\n",
       "      <td>taste flavour toothpaste good refreshingelimin...</td>\n",
       "      <td>flavour good</td>\n",
       "      <td>{'neg': 0.115, 'neu': 0.729, 'pos': 0.155, 'co...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Seysmail</td>\n",
       "      <td>5</td>\n",
       "      <td>13-01-2024</td>\n",
       "      <td>worth price</td>\n",
       "      <td>nice</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'comp...</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Suresh Singh</td>\n",
       "      <td>5</td>\n",
       "      <td>26-12-2023</td>\n",
       "      <td>good product</td>\n",
       "      <td>nice</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zaki</td>\n",
       "      <td>4</td>\n",
       "      <td>10-02-2024</td>\n",
       "      <td>good toothpaste usesmell good</td>\n",
       "      <td>dabur miswak</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'comp...</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>4</td>\n",
       "      <td>17-01-2024</td>\n",
       "      <td>good</td>\n",
       "      <td>paste</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Abhi</td>\n",
       "      <td>4</td>\n",
       "      <td>08-01-2024</td>\n",
       "      <td>good toothpaste</td>\n",
       "      <td>good</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'comp...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Abhay</td>\n",
       "      <td>4</td>\n",
       "      <td>18-12-2023</td>\n",
       "      <td>good paste</td>\n",
       "      <td>good paste</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>4</td>\n",
       "      <td>16-12-2023</td>\n",
       "      <td>pastehas long expiry</td>\n",
       "      <td>good product standard delivery decent price</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Prasanna Bhat</td>\n",
       "      <td>5</td>\n",
       "      <td>13-02-2024</td>\n",
       "      <td>good buy</td>\n",
       "      <td>worth</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'comp...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sandeep kkr</td>\n",
       "      <td>4</td>\n",
       "      <td>03-12-2023</td>\n",
       "      <td>toothpaste mein saunf ki heavy smell hai baki ...</td>\n",
       "      <td>ok toothpaste</td>\n",
       "      <td>{'neg': 0.145, 'neu': 0.699, 'pos': 0.156, 'co...</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Obito uchiha</td>\n",
       "      <td>5</td>\n",
       "      <td>31-01-2024</td>\n",
       "      <td>ice</td>\n",
       "      <td>best</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AB</td>\n",
       "      <td>4</td>\n",
       "      <td>05-12-2023</td>\n",
       "      <td>fragrance good ï½ï</td>\n",
       "      <td>overall good</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'comp...</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Raj Mavani</td>\n",
       "      <td>4</td>\n",
       "      <td>28-11-2023</td>\n",
       "      <td>buy small children sweetness ï½ï</td>\n",
       "      <td>product nice little bit sweet</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pavan Naik</td>\n",
       "      <td>5</td>\n",
       "      <td>21-01-2024</td>\n",
       "      <td>indian products dam good</td>\n",
       "      <td>worth</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Harichandan maharana</td>\n",
       "      <td>4</td>\n",
       "      <td>15-11-2023</td>\n",
       "      <td>defective product returned money back within days</td>\n",
       "      <td>defective product received</td>\n",
       "      <td>{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Rating        Date  \\\n",
       "0         Dharmesh Tolia       5  27-01-2024   \n",
       "1            Rohit yadav       4  26-01-2024   \n",
       "2               Anabayan       5  29-01-2024   \n",
       "3            Placeholder       5  29-12-2023   \n",
       "4                      G       3  04-01-2024   \n",
       "5    vinay sainath reddy       4  02-02-2024   \n",
       "6               Seysmail       5  13-01-2024   \n",
       "7           Suresh Singh       5  26-12-2023   \n",
       "8                   Zaki       4  10-02-2024   \n",
       "9                  Vikas       4  17-01-2024   \n",
       "10                  Abhi       4  08-01-2024   \n",
       "11                 Abhay       4  18-12-2023   \n",
       "12       Amazon Customer       4  16-12-2023   \n",
       "13         Prasanna Bhat       5  13-02-2024   \n",
       "14           Sandeep kkr       4  03-12-2023   \n",
       "15          Obito uchiha       5  31-01-2024   \n",
       "16                    AB       4  05-12-2023   \n",
       "17            Raj Mavani       4  28-11-2023   \n",
       "18            Pavan Naik       5  21-01-2024   \n",
       "19  Harichandan maharana       4  15-11-2023   \n",
       "\n",
       "                                               Review  \\\n",
       "0   dabur meswak complete oral care toothpaste gam...   \n",
       "1   dabur meswak complete oral care toothpaste use...   \n",
       "2                           unique taste good product   \n",
       "3                         first time use product nice   \n",
       "4   quality definitely since start product disappo...   \n",
       "5   taste flavour toothpaste good refreshingelimin...   \n",
       "6                                         worth price   \n",
       "7                                        good product   \n",
       "8                       good toothpaste usesmell good   \n",
       "9                                                good   \n",
       "10                                    good toothpaste   \n",
       "11                                         good paste   \n",
       "12                               pastehas long expiry   \n",
       "13                                           good buy   \n",
       "14  toothpaste mein saunf ki heavy smell hai baki ...   \n",
       "15                                                ice   \n",
       "16                                 fragrance good ï½ï   \n",
       "17                   buy small children sweetness ï½ï   \n",
       "18                           indian products dam good   \n",
       "19  defective product returned money back within days   \n",
       "\n",
       "                                          Title  \\\n",
       "0        toothpaste holistic approach oral care   \n",
       "1    dabur meswak complete oral care toothpaste   \n",
       "2                     unique taste good product   \n",
       "3                                  good product   \n",
       "4                                    use better   \n",
       "5                                  flavour good   \n",
       "6                                          nice   \n",
       "7                                          nice   \n",
       "8                                  dabur miswak   \n",
       "9                                         paste   \n",
       "10                                         good   \n",
       "11                                   good paste   \n",
       "12  good product standard delivery decent price   \n",
       "13                                        worth   \n",
       "14                                ok toothpaste   \n",
       "15                                         best   \n",
       "16                                 overall good   \n",
       "17                product nice little bit sweet   \n",
       "18                                        worth   \n",
       "19                   defective product received   \n",
       "\n",
       "                                                Score  Compound Sentiment  \n",
       "0   {'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...    0.9879  positive  \n",
       "1   {'neg': 0.0, 'neu': 0.57, 'pos': 0.43, 'compou...    0.9575  positive  \n",
       "2   {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...    0.4404  positive  \n",
       "3   {'neg': 0.0, 'neu': 0.646, 'pos': 0.354, 'comp...    0.6690  positive  \n",
       "4   {'neg': 0.196, 'neu': 0.633, 'pos': 0.171, 'co...   -0.1027  negative  \n",
       "5   {'neg': 0.115, 'neu': 0.729, 'pos': 0.155, 'co...    0.4019  positive  \n",
       "6   {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'comp...    0.2263  positive  \n",
       "7   {'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...    0.4404  positive  \n",
       "8   {'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'comp...    0.7003  positive  \n",
       "9   {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...    0.4404  positive  \n",
       "10  {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'comp...    0.4404  positive  \n",
       "11  {'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...    0.4404  positive  \n",
       "12  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  \n",
       "13  {'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'comp...    0.4404  positive  \n",
       "14  {'neg': 0.145, 'neu': 0.699, 'pos': 0.156, 'co...    0.0516  positive  \n",
       "15  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  \n",
       "16  {'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'comp...    0.4927  positive  \n",
       "17  {'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...    0.4939  positive  \n",
       "18  {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...    0.4404  positive  \n",
       "19  {'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'comp...   -0.4404  negative  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd2e68",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc97e3c0",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Feature Engineering\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4211a",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Rating\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec766b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_rating(text, dataframe) -> pd.core.frame.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Function that extracts the customer's rating and converts it to a float.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str or pandas.core.series.Series\n",
    "#         Text from which to extract the client's note.\n",
    "    \n",
    "#     dataframe : pandas.core.frame.DataFrame\n",
    "#         Dataframe that allows the extraction of the final results.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pandas.core.frame.DataFrame\n",
    "#         Dataframe that contains the final result.\n",
    "\n",
    "#     \"\"\"\n",
    "#     rating = []\n",
    "#     for i in range(0, len(text)):\n",
    "#         row = text[i].split(\" \")\n",
    "#         row = row[0].replace(\",\", \".\")\n",
    "#         row = float(row)\n",
    "#         rating.append(row)\n",
    "    \n",
    "#     df_data = pd.DataFrame({\"New rating\": rating})\n",
    "#     dataframe = pd.concat([dataframe, df_data[\"New rating\"]], axis=1)\n",
    "    \n",
    "#     return dataframe\n",
    "\n",
    "# df_data = feature_rating(text=df_data[\"Rating\"], dataframe=df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945a703",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Date\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66e9b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_date(text, dataframe) -> pd.core.frame.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Function to extract the date from a text and convert it to datetime.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str or pandas.core.series.Series\n",
    "#         Text from which to extract the review's date.\n",
    "    \n",
    "#     dataframe : pandas.core.frame.DataFrame\n",
    "#         Dataframe that allows the extraction of the final results.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pandas.core.frame.DataFrame\n",
    "#         Dataframe that contains the final result.\n",
    "\n",
    "#     \"\"\"\n",
    "#     root = {\n",
    "#         \"January\": \"01\", \"january\": \"01\",\n",
    "#         \"February\": \"02\", \"february\": \"02\",\n",
    "#         \"March\": \"03\", \"march\": \"03\",\n",
    "#         \"April\": \"04\", \"april\": \"04\",\n",
    "#         \"May\": \"05\", \"may\": \"05\",\n",
    "#         \"June\": \"06\", \"june\": \"06\",\n",
    "#         \"July\": \"07\", \"july\": \"07\",\n",
    "#         \"August\": \"08\", \"august\": \"08\",\n",
    "#         \"September\": \"09\", \"september\": \"09\",\n",
    "#         \"0ctober\": \"10\", \"october\": \"10\",\n",
    "#         \"November\": \"11\", \"november\": \"11\",\n",
    "#         \"December\": \"12\", \"december\": \"12\"\n",
    "#     }\n",
    "\n",
    "#     date = []\n",
    "#     for i in range(0, len(text)):\n",
    "#         row = text[i].split(\" \")\n",
    "#         row = row[7] + \" \" + row[6] + \" \" + row[8]\n",
    "#         date.append(row)\n",
    "\n",
    "#     datetime = [word.split(\" \") for word in date]\n",
    "\n",
    "#     date = []\n",
    "#     for element in datetime:\n",
    "#         for key, value in root.items():\n",
    "#             if key not in element:\n",
    "#                 continue\n",
    "\n",
    "#             index = element.index(key)\n",
    "#             element[index] = value\n",
    "#         row = \"/\".join(element)\n",
    "#         date.append(row)\n",
    "    \n",
    "#     df_data = pd.DataFrame({\"New date\": date})\n",
    "#     df_data[\"New date\"] = pd.to_datetime(df_data[\"New date\"])\n",
    "#     dataframe = pd.concat([dataframe, df_data[\"New date\"]], axis=1)\n",
    "    \n",
    "#     return dataframe\n",
    "\n",
    "# df_data = feature_date(text=df_data[\"Date\"], dataframe=df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94263d88",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            3) Verified purchase\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24b9f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data[\"Verified Purchase\"].replace(\n",
    "#     to_replace=\"Verified Purchase\",\n",
    "#     value=\"Yes\",\n",
    "#     inplace=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5fb35d",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            4) Country\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7a94c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_country(text, dataframe) -> pd.core.frame.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Function to extract the country from a text.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str or pandas.core.series.Series\n",
    "#         Text from which to extract the review's country.\n",
    "    \n",
    "#     dataframe : pandas.core.frame.DataFrame\n",
    "#         Dataframe that allows the extraction of the final results.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pandas.core.frame.DataFrame\n",
    "#         Dataframe that contains the final result.\n",
    "\n",
    "#     \"\"\"\n",
    "#     country = []\n",
    "#     for i in range(0, len(text)):\n",
    "#         row = text[i].split(\" \")\n",
    "#         row = row[3] + \" \" + row[4]\n",
    "#         country.append(row)\n",
    "    \n",
    "#     df_data = pd.DataFrame({\"Country\": country})\n",
    "#     dataframe = pd.concat([dataframe, df_data[\"Country\"]], axis=1)\n",
    "    \n",
    "#     return dataframe\n",
    "\n",
    "# df_data = feature_country(text=df_data[\"Date\"], dataframe=df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f14377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dharmesh Tolia</td>\n",
       "      <td>5</td>\n",
       "      <td>27-01-2024</td>\n",
       "      <td>dabur meswak complete oral care toothpaste gam...</td>\n",
       "      <td>toothpaste holistic approach oral care</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit yadav</td>\n",
       "      <td>4</td>\n",
       "      <td>26-01-2024</td>\n",
       "      <td>dabur meswak complete oral care toothpaste use...</td>\n",
       "      <td>dabur meswak complete oral care toothpaste</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.57, 'pos': 0.43, 'compou...</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anabayan</td>\n",
       "      <td>5</td>\n",
       "      <td>29-01-2024</td>\n",
       "      <td>unique taste good product</td>\n",
       "      <td>unique taste good product</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Rating        Date  \\\n",
       "0  Dharmesh Tolia       5  27-01-2024   \n",
       "1     Rohit yadav       4  26-01-2024   \n",
       "2        Anabayan       5  29-01-2024   \n",
       "\n",
       "                                              Review  \\\n",
       "0  dabur meswak complete oral care toothpaste gam...   \n",
       "1  dabur meswak complete oral care toothpaste use...   \n",
       "2                          unique taste good product   \n",
       "\n",
       "                                        Title  \\\n",
       "0      toothpaste holistic approach oral care   \n",
       "1  dabur meswak complete oral care toothpaste   \n",
       "2                   unique taste good product   \n",
       "\n",
       "                                               Score  Compound Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...    0.9879  positive  \n",
       "1  {'neg': 0.0, 'neu': 0.57, 'pos': 0.43, 'compou...    0.9575  positive  \n",
       "2  {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...    0.4404  positive  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2f2e4",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e9bf0",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Data export\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "36b2e2c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'amzn_customer_reviews_pre.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamzn_customer_reviews_pre.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programming\\anaconda3\\envs\\hackathon\\lib\\site-packages\\pandas\\core\\generic.py:3466\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3455\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3457\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3458\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3459\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3463\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3464\u001b[0m )\n\u001b[1;32m-> 3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programming\\anaconda3\\envs\\hackathon\\lib\\site-packages\\pandas\\io\\formats\\format.py:1105\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1087\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1088\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1103\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1104\u001b[0m )\n\u001b[1;32m-> 1105\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mD:\\Programming\\anaconda3\\envs\\hackathon\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:237\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    248\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    249\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mD:\\Programming\\anaconda3\\envs\\hackathon\\lib\\site-packages\\pandas\\io\\common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'amzn_customer_reviews_pre.csv'"
     ]
    }
   ],
   "source": [
    "df_data.to_csv(path_or_buf=\"amzn_customer_reviews_pre.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a917c-7017-4778-abf4-fb067bc69601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
